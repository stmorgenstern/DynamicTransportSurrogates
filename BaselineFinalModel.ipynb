{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae859336",
   "metadata": {},
   "source": [
    "# Baseline Full Integration Model - Final Model Building and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f14504",
   "metadata": {},
   "source": [
    "Import Julia machine learning packages, plotting package, and file loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce70021",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux,Statistics,Plots,MLDataUtils,DelimitedFiles\n",
    "using Flux.Data: DataLoader\n",
    "include(\"utilityfunc.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be05e77f",
   "metadata": {},
   "source": [
    "Set the upper and lower bounds on the features and define the scaling and unscaling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a27e836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Float32}:\n",
       "  5.0f-6\n",
       "  5.0f-6\n",
       " 30.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set lower and upper bounds on Lpt, Kt, Rs,(Lpt is first element, Kt is second element, Rs is the third element)\n",
    "lb=Float32[5e-7,5e-7,5]\n",
    "ub=Float32[5e-6,5e-6,30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f3390b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inv_oscaler (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define scaler functions to preprocess data\n",
    "conc_ub=Float32(.6)\n",
    "\n",
    "iscaler(x)=(x-lb)./(ub-lb) #Min-Max Normalization on Features\n",
    "inv_iscaler(x)=x.*(ub.-lb).+lb\n",
    "oscaler(x)= x ./ conc_ub#Min-Max Normalization on Targets\n",
    "inv_oscaler(x)=x.*conc_ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc038a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iscalerbatch (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function iscalerbatch(x)\n",
    "    nfeat,sl = size(x)\n",
    "    out=Array{Float32,2}(undef,nfeat,sl)\n",
    "    for i=1:sl\n",
    "        out[:,i]=iscaler(x[:,i])\n",
    "    end\n",
    "    return out\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62018489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inv_iscalerbatch (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function inv_iscalerbatch(x)\n",
    "    nfeat,sl = size(x)\n",
    "    out=Array{Float32,2}(undef,nfeat,sl)\n",
    "    for i=1:sl\n",
    "        out[:,i]=inv_iscaler(x[:,i])\n",
    "    end\n",
    "    return out\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72ee9c8",
   "metadata": {},
   "source": [
    "Define model characteristics, load the data, reshape the data into proper form, and scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae89d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samp=Int64(1e4); # number of samples\n",
    "nbatch = n_samp; # number of batches\n",
    "nfeat=3; #5 features\n",
    "ntarg=20; #1 target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "380dba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = readdlm(\"MLFinalData_v3.csv\",',',Float32)\n",
    "X_p= d[1:5,:];\n",
    "Y_p= d[6,:];\n",
    "X=Array{Float32,2}(undef,3,n_samp)\n",
    "for i=1:n_samp\n",
    "    X[:,i]=X_p[1:3,20*i]\n",
    "end\n",
    "Y=reshape(Y_p,(20,n_samp));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbdb716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=iscalerbatch(X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "909da90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Float32.(oscaler(Y));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d2c3b7",
   "metadata": {},
   "source": [
    "Shuffle the data, split the data into training, validation, and test sets using 80/10/10 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b116486",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs,Ys=shuffleobs((X, Y));\n",
    "(x_train, y_train), (x_val, y_val),(x_test, y_test) = splitobs((Xs, Ys), at = (0.8,.10) );\n",
    "data = DataLoader((x_train,y_train));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f947f3db",
   "metadata": {},
   "source": [
    "Define model structure- here we use 2 hidden layers with 8 nodes and the ReLU activation function and the MSE loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63d2bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden=8;\n",
    "activation_func=Flux.relu\n",
    "function loss(x, y)\n",
    "     Flux.mse(m_baseline(x), y)\n",
    "end\n",
    "m_baseline = Chain(Dense(nfeat,n_hidden),Dense(n_hidden,n_hidden,activation_func),Dense(n_hidden,n_hidden,activation_func),Dense(n_hidden,ntarg))\n",
    "ps = params(m_baseline)\n",
    "ϵ=2.5e-6; #Early stopping criteria\n",
    "opt= ADAM(5e-4);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76471091",
   "metadata": {},
   "source": [
    "Train for 100 epochs using the ADAM optimizer with an exponentially decaying learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2849fc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100;\n",
    "e_log = zeros(n_epochs)\n",
    "decay(epoch)=1e-3*exp(-.023*epoch)\n",
    "for i=1:100\n",
    "    Flux.train!(loss, ps, data, ADAM(decay(i)))\n",
    "    e_log[i]=loss(x_val,y_val)\n",
    "    if (i%1 == 0 || i ==1)\n",
    "        @show(i,e_log[i])\n",
    "    end\n",
    "    if (e_log[i]<ϵ)\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f72755",
   "metadata": {},
   "source": [
    "Evaluate performance metrics on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9eabd78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(x_test, y_test) = 6.2188738f-6\n",
      "sqrt(loss(x_test, y_test)) = 0.002493767f0\n",
      "mean_error_func(x_test, y_test, m_baseline) = 0.9576018f0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9576018f0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show loss(x_test,y_test)\n",
    "@show sqrt(loss(x_test,y_test))\n",
    "@show mean_error_func(x_test,y_test,m_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fb75af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the model (uncomment code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23848f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "using BSON: @save\n",
    "#@save \"m_baseline.bson\" m_baseline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
