{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e5c1498",
   "metadata": {},
   "source": [
    "# Dynamic Models - Grid Search and Model Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e7ba9",
   "metadata": {},
   "source": [
    "Import Julia machine learning packages, plotting package, and file loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce70021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evalmpe (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux,Statistics,Plots,MLDataUtils,DelimitedFiles\n",
    "using Flux.Data: DataLoader\n",
    "include(\"utilityfunc.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d74d99",
   "metadata": {},
   "source": [
    "Define the upper and lower bounds on the features and define the scaling and unscaling functions that execute min-max normalization on the features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f3390b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inv_oscaler (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Target upper bound\n",
    "conc_ub=.6\n",
    "#feature lower and upper bound\n",
    "i_lb=Float32[5e-7,7e-7,5.0,0.0,0.0] \n",
    "i_ub=Float32[5e-6,5e-6,30,(300/3600),conc_ub]\n",
    "iscaler(x)=(x-i_lb)./(i_ub-i_lb) \n",
    "inv_iscaler(x)=x.*(i_ub.-i_lb).+i_lb\n",
    "oscaler(x)= x ./ conc_ub\n",
    "inv_oscaler(x)=x.*conc_ub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10046fc2",
   "metadata": {},
   "source": [
    "Load in the data and scale the features and output then split into training/testing/validation with 80/10/10 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be1939b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = readdlm(\"MLFinalData_v3.csv\",',',Float32)\n",
    "X= iscalerbatch(d[1:5,:]);\n",
    "Y= Float32.(oscaler.(d[6,:]));\n",
    "(xtrg, ytrg), (xtg, ytg),(xtest,ytest) = splitobs((X, Y), at = (0.8,.1) );\n",
    "datatrg=DataLoader((xtrg, ytrg));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a47703b",
   "metadata": {},
   "source": [
    "Define the MSE loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdf479e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "closs (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function closs(x,y,nn)\n",
    "    Flux.reset!(nn)\n",
    "     Flux.mse(nn(x), y)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc78865",
   "metadata": {},
   "source": [
    "Set training hyperparameters - 50 epochs, ADAM with a fixed learning rate of 10^-3\n",
    "\n",
    "Then set the number of features=5,target=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94e3f560",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train,x_val,y_val = datatrg,xtg,ytg\n",
    "opt= ADAM(1e-3)\n",
    "n_epochs = 50;\n",
    "nfeat =5; ntarg =1;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a740f2b",
   "metadata": {},
   "source": [
    "Execute grid search to assess 12 candidate models for the Dynamic MLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be198996",
   "metadata": {},
   "source": [
    "We vary the number of hidden layer (1-2), the activation function (tanh/ReLU), and the number of nodes per hidden layer (8,16,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf09b6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning grid search for MLP:\n",
      "beginning model 1\n",
      "beginning model 2\n",
      "beginning model 3\n",
      "beginning model 4"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      "  [1] try_yieldto(undo::typeof(Base.ensure_rescheduled))",
      "    @ Base .\\task.jl:710",
      "  [2] wait",
      "    @ .\\task.jl:769 [inlined]",
      "  [3] uv_write(s::Base.PipeEndpoint, p::Ptr{UInt8}, n::UInt64)",
      "    @ Base .\\stream.jl:992",
      "  [4] unsafe_write(s::Base.PipeEndpoint, p::Ptr{UInt8}, n::UInt64)",
      "    @ Base .\\stream.jl:1064",
      "  [5] unsafe_write",
      "    @ .\\io.jl:361 [inlined]",
      "  [6] write",
      "    @ .\\strings\\io.jl:185 [inlined]",
      "  [7] print",
      "    @ .\\strings\\io.jl:187 [inlined]",
      "  [8] print(::IJulia.IJuliaStdio{Base.PipeEndpoint}, ::String, ::String)",
      "    @ Base .\\strings\\io.jl:46",
      "  [9] println(io::IJulia.IJuliaStdio{Base.PipeEndpoint}, xs::String)",
      "    @ Base .\\strings\\io.jl:73",
      " [10] println(xs::String)",
      "    @ Base .\\coreio.jl:4",
      " [11] top-level scope",
      "    @ In[6]:22",
      " [12] eval",
      "    @ .\\boot.jl:360 [inlined]",
      " [13] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base .\\loading.jl:1094"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nh_8,nh_16,nh_32 = 8,16,32; #candidate number of nodes\n",
    "n_MLP=12 #12 canidate models\n",
    "println(\"Beginning grid search for MLP:\") \n",
    "m_list_MLP = [Chain(Dense(nfeat,nh_8),Dense(nh_8, nh_8,Flux.tanh),Dense(nh_8,ntarg))\n",
    "    Chain(Dense(nfeat,nh_8),Dense(nh_8, nh_8,Flux.tanh),Dense(nh_8, nh_8,Flux.tanh),Dense(nh_8,ntarg))\n",
    "        Chain(Dense(nfeat,nh_8),Dense(nh_8, nh_8,Flux.relu),Dense(nh_8,ntarg))\n",
    "    Chain(Dense(nfeat,nh_8),Dense(nh_8, nh_8,Flux.relu),Dense(nh_8, nh_8,Flux.relu),Dense(nh_8,ntarg))\n",
    "        Chain(Dense(nfeat,nh_16),Dense(nh_16, nh_16,Flux.tanh),Dense(nh_16,ntarg))\n",
    "    Chain(Dense(nfeat,nh_16),Dense(nh_16, nh_16,Flux.tanh),Dense(nh_16, nh_16,Flux.tanh),Dense(nh_16,ntarg))\n",
    "        Chain(Dense(nfeat,nh_16),Dense(nh_16, nh_16,Flux.relu),Dense(nh_16,ntarg))\n",
    "    Chain(Dense(nfeat,nh_16),Dense(nh_16, nh_16,Flux.relu),Dense(nh_16, nh_16,Flux.relu),Dense(nh_16,ntarg))\n",
    "        Chain(Dense(nfeat,nh_32),Dense(nh_32, nh_32,Flux.tanh),Dense(nh_32,ntarg))\n",
    "    Chain(Dense(nfeat,nh_32),Dense(nh_32, nh_32,Flux.tanh),Dense(nh_32, nh_32,Flux.tanh),Dense(nh_32,ntarg))\n",
    "        Chain(Dense(nfeat,nh_32),Dense(nh_32, nh_32,Flux.relu),Dense(nh_32,ntarg))\n",
    "    Chain(Dense(nfeat,nh_32),Dense(nh_32, nh_32,Flux.relu),Dense(nh_32, nh_32,Flux.relu),Dense(nh_32,ntarg))\n",
    "    ]\n",
    "    record_MLP = Array{Any,2}(undef,2,n_MLP);\n",
    "        record_MLP[1,:]=[\"8tanh1\" \"8tanh2\" \"8relu1\" \"8relu2\"\n",
    "    \"16tanh1\" \"16tanh2\" \"16relu1\" \"16relu2\"\n",
    "        \"32tanh1\" \"32tanh2\" \"32relu1\" \"32relu2\"]\n",
    "for i=1:n_MLP\n",
    "    println(\"beginning model $i\")\n",
    "    iloss(x,y)=closs(x,y,m_list_MLP[i])\n",
    "    Flux.reset!(m_list_MLP[i])\n",
    "    ps = params(m_list_MLP[i])\n",
    "    for i=1:n_epochs\n",
    "        Flux.train!(iloss, ps, data_train, opt)\n",
    "    end\n",
    "    record_MLP[2,i]=iloss(x_val,y_val)\n",
    "end\n",
    "@show record_MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2967fd9",
   "metadata": {},
   "source": [
    "Execute grid search to assess 6 candidate models for the Dynamic RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f324ea",
   "metadata": {},
   "source": [
    "We vary the number of hidden layer (1-2) and the number of nodes per hidden layer (8,16,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11220758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning grid search for RNN:\n",
      "beginning model 1\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      "  [1] try_yieldto(undo::typeof(Base.ensure_rescheduled))",
      "    @ Base .\\task.jl:710",
      "  [2] wait",
      "    @ .\\task.jl:769 [inlined]",
      "  [3] uv_write(s::Base.PipeEndpoint, p::Ptr{UInt8}, n::UInt64)",
      "    @ Base .\\stream.jl:992",
      "  [4] unsafe_write(s::Base.PipeEndpoint, p::Ptr{UInt8}, n::UInt64)",
      "    @ Base .\\stream.jl:1064",
      "  [5] unsafe_write",
      "    @ .\\io.jl:361 [inlined]",
      "  [6] write",
      "    @ .\\strings\\io.jl:185 [inlined]",
      "  [7] print",
      "    @ .\\strings\\io.jl:187 [inlined]",
      "  [8] print(::IJulia.IJuliaStdio{Base.PipeEndpoint}, ::String, ::String)",
      "    @ Base .\\strings\\io.jl:46",
      "  [9] println(io::IJulia.IJuliaStdio{Base.PipeEndpoint}, xs::String)",
      "    @ Base .\\strings\\io.jl:73",
      " [10] println(xs::String)",
      "    @ Base .\\coreio.jl:4",
      " [11] top-level scope",
      "    @ In[7]:14",
      " [12] eval",
      "    @ .\\boot.jl:360 [inlined]",
      " [13] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base .\\loading.jl:1094"
     ]
    }
   ],
   "source": [
    "n_RNN=6\n",
    "println(\"Beginning grid search for RNN:\")\n",
    "m_list_RNN = [Chain(Dense(nfeat,nh_8),RNN(nh_8, nh_8),Dense(nh_8,ntarg))\n",
    "    Chain(Dense(nfeat,nh_8),RNN(nh_8, nh_8),RNN(nh_8, nh_8),Dense(nh_8,ntarg))\n",
    "    Chain(Dense(nfeat,nh_16),RNN(nh_16, nh_16),Dense(nh_16,ntarg))\n",
    "    Chain(Dense(nfeat,nh_16),RNN(nh_16, nh_16),RNN(nh_16, nh_16),Dense(nh_16,ntarg))\n",
    "    Chain(Dense(nfeat,nh_32),RNN(nh_32, nh_32),Dense(nh_32,ntarg))\n",
    "    Chain(Dense(nfeat,nh_32),RNN(nh_32, nh_32),RNN(nh_32, nh_32),Dense(nh_32,ntarg))]\n",
    "        record_RNN = Array{Any,2}(undef,2,n_RNN);\n",
    "        record_RNN[1,:]=[\"8/1\" \"8/2\"\n",
    "    \"16/1\" \"16/2\"\n",
    "        \"32/1\" \"32/2\"]\n",
    "for i=1:n_RNN\n",
    "    println(\"beginning model $i\")\n",
    "    iloss(x,y)=closs(x,y,m_list_RNN[i])\n",
    "    Flux.reset!(m_list_RNN[i])\n",
    "    ps = params(m_list_RNN[i])\n",
    "    for i=1:n_epochs\n",
    "        Flux.train!(iloss, ps, data_train, opt)\n",
    "    end\n",
    "    record_RNN[2,i]=iloss(x_val,y_val)\n",
    "end\n",
    "@show record_RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef5a7e2",
   "metadata": {},
   "source": [
    "Execute grid search to assess 6 candidate models for the Dynamic RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37461729",
   "metadata": {},
   "source": [
    "We vary the number of hidden layer (1-2) and the number of nodes per hidden layer (8,16,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd2e585b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning grid search for LSTM:\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      "  [1] try_yieldto(undo::typeof(Base.ensure_rescheduled))",
      "    @ Base .\\task.jl:710",
      "  [2] wait",
      "    @ .\\task.jl:769 [inlined]",
      "  [3] uv_write(s::Base.PipeEndpoint, p::Ptr{UInt8}, n::UInt64)",
      "    @ Base .\\stream.jl:992",
      "  [4] unsafe_write(s::Base.PipeEndpoint, p::Ptr{UInt8}, n::UInt64)",
      "    @ Base .\\stream.jl:1064",
      "  [5] unsafe_write",
      "    @ .\\io.jl:361 [inlined]",
      "  [6] write",
      "    @ .\\strings\\io.jl:185 [inlined]",
      "  [7] print",
      "    @ .\\strings\\io.jl:187 [inlined]",
      "  [8] print(::IJulia.IJuliaStdio{Base.PipeEndpoint}, ::String, ::String)",
      "    @ Base .\\strings\\io.jl:46",
      "  [9] println(io::IJulia.IJuliaStdio{Base.PipeEndpoint}, xs::String)",
      "    @ Base .\\strings\\io.jl:73",
      " [10] println(xs::String)",
      "    @ Base .\\coreio.jl:4",
      " [11] top-level scope",
      "    @ In[8]:2",
      " [12] eval",
      "    @ .\\boot.jl:360 [inlined]",
      " [13] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base .\\loading.jl:1094"
     ]
    }
   ],
   "source": [
    "n_LSTM=6;\n",
    "println(\"Beginning grid search for LSTM:\")\n",
    "m_list_LSTM = [Chain(Dense(nfeat,nh_8),LSTM(nh_8, nh_8),Dense(nh_8,ntarg))\n",
    "    Chain(Dense(nfeat,nh_8),LSTM(nh_8, nh_8),LSTM(nh_8, nh_8),Dense(nh_8,ntarg))\n",
    "    Chain(Dense(nfeat,nh_16),LSTM(nh_16, nh_16),Dense(nh_16,ntarg))\n",
    "    Chain(Dense(nfeat,nh_16),LSTM(nh_16, nh_16),LSTM(nh_16, nh_16),Dense(nh_16,ntarg))\n",
    "    Chain(Dense(nfeat,nh_32),LSTM(nh_32, nh_32),Dense(nh_32,ntarg))\n",
    "    Chain(Dense(nfeat,nh_32),LSTM(nh_32, nh_32),LSTM(nh_32, nh_32),Dense(nh_32,ntarg))]\n",
    "record_LSTM  = Array{Any,2}(undef,2,n_LSTM);\n",
    "record_LSTM[1,:]=[\"8/1\" \"8/2\"\n",
    "    \"16/1\" \"16/2\"\n",
    "        \"32/1\" \"32/2\"]\n",
    "for i=1:n_LSTM\n",
    "    println(\"beginning model $i\")\n",
    "    iloss(x,y)=closs(x,y,m_list_LSTM[i])\n",
    "    Flux.reset!(m_list_LSTM[i])\n",
    "    ps = params(m_list_LSTM[i])\n",
    "    for i=1:n_epochs\n",
    "        Flux.train!(iloss, ps, data_train, opt)\n",
    "    end\n",
    "    @show record_LSTM[2,i]=iloss(x_val,y_val)\n",
    "end\n",
    "@show record_LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09851ab5",
   "metadata": {},
   "source": [
    "A record of the original grid search run is saved in the file \"record of grid search\".xlsx -> it is important to note training is computationally expensive and stochastic and that any further runs may take a long time and not match the original"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
